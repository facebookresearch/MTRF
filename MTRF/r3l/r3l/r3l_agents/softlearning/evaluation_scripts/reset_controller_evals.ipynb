{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "checkpoint_dirs = [d for d in glob.glob(str(path / \"*\")) if 'checkpoint' in d and os.path.isdir(d)]\n",
    "checkpoint_dirs.sort(key=lambda s: int(s.split(\"_\")[-1]))\n",
    "\n",
    "import r3l\n",
    "import gym\n",
    "from r3l.r3l_envs.inhand_env.pickup import SawyerDhandInHandObjectPickupFixed\n",
    "from softlearning.environments.adapters.gym_adapter import GymAdapter\n",
    "\n",
    "env = GymAdapter(\"SawyerDhandInHandValve3\", \"PickupFixed-v0\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from softlearning.policies.utils import get_policy_from_variant\n",
    "from softlearning.models.utils import flatten_input_structure\n",
    "\n",
    "def load_policy_from_checkpoint(ckpt_path, env):\n",
    "    # Load policy\n",
    "    with open(os.path.join(ckpt_dir, \"policy_params.pkl\"), \"rb\") as f:\n",
    "        policy_params = pickle.load(f)\n",
    "        \n",
    "    with open(os.path.join(ckpt_dir, \"..\", \"params.pkl\"), \"rb\") as f:\n",
    "        variant = pickle.load(f)\n",
    "        \n",
    "    pickup_params = policy_params[0]\n",
    "\n",
    "    policy = get_policy_from_variant(variant, env)\n",
    "    policy.set_weights(pickup_params)\n",
    "    return wrap_policy(policy)\n",
    "\n",
    "def wrap_policy(policy):\n",
    "    def wrapped_policy(obs_dict):\n",
    "        feed_dict = {\n",
    "            key: obs_dict[key][None, ...]\n",
    "            for key in policy.observation_keys\n",
    "        }\n",
    "        observation = flatten_input_structure(feed_dict)\n",
    "        with policy.set_deterministic(True):\n",
    "            action = policy.actions_np(observation)[0]\n",
    "        return action\n",
    "    return wrapped_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EVAL_EPISODES = 1\n",
    "T = 50\n",
    "\n",
    "success_rates = []\n",
    "obs_dicts_per_policy = []\n",
    "for ckpt_dir in checkpoint_dirs[::2]:\n",
    "    print(\"EVALUATING CHECKPOINT: \", ckpt_dir.split(\"_\")[-1])\n",
    "    policy = load_policy_from_checkpoint(ckpt_dir, env)\n",
    "    \n",
    "    successes = []\n",
    "    obs_dicts = []\n",
    "    for ep in range(N_EVAL_EPISODES):\n",
    "        env.reset()\n",
    "        for t in range(T):\n",
    "            env.step(policy(env.get_obs_dict()))\n",
    "        obs_dict = env.get_obs_dict()\n",
    "        success = obs_dict[\"object_xyz\"][2] > 0.85\n",
    "        successes.append(success)\n",
    "        obs_dicts.append(obs_dict)\n",
    "    success_rate = np.array(successes).astype(int).mean()\n",
    "    print(\"success % = \", success_rate)\n",
    "    success_rates.append(success_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
